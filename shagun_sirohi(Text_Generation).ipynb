{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "abjAXrpXgITP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentiment 140 dataset\n",
        "# You can download the dataset from: http://help.sentiment140.com/for-students/\n",
        "# Extract the training set and put it in a file named 'training.1600000.processed.noemoticon.csv'\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_path = '/content/training.1600000.processed.noemoticon.csv'"
      ],
      "metadata": {
        "id": "rXauwsXdgbP-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = []\n",
        "labels = []\n",
        "with open(dataset_path, 'r', encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        parts = line.split(',')\n",
        "        sentiment = int(parts[0].strip('\"'))  # Remove double quotes around sentiment value\n",
        "        tweet = ','.join(parts[5:])\n",
        "        tweets.append(tweet)\n",
        "        labels.append(sentiment)"
      ],
      "metadata": {
        "id": "tlPTaGdogmu1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the tweets\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets)\n",
        "sequences = tokenizer.texts_to_sequences(tweets)"
      ],
      "metadata": {
        "id": "vZ4TNbj4hkxp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to have the same length\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "6s2k8smahsIy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "QfRBZBHUhygK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_ek6jmlph2Ti"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_DAMtuaUh5xo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(sequences, labels, batch_size=128, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdBpEYYGh-cN",
        "outputId": "ef4d7670-39bd-40fe-827e-acece5db2604"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1142/1142 [==============================] - 696s 606ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 3.6625e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1142/1142 [==============================] - 683s 598ms/step - loss: 2.2235e-06 - accuracy: 1.0000 - val_loss: 1.3428e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1142/1142 [==============================] - 679s 595ms/step - loss: 9.4477e-07 - accuracy: 1.0000 - val_loss: 6.5245e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1142/1142 [==============================] - 674s 590ms/step - loss: 4.8414e-07 - accuracy: 1.0000 - val_loss: 3.5151e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1142/1142 [==============================] - 672s 589ms/step - loss: 2.6698e-07 - accuracy: 1.0000 - val_loss: 1.9812e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1142/1142 [==============================] - 665s 582ms/step - loss: 1.5206e-07 - accuracy: 1.0000 - val_loss: 1.1394e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1142/1142 [==============================] - 665s 582ms/step - loss: 8.7858e-08 - accuracy: 1.0000 - val_loss: 6.6107e-08 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1142/1142 [==============================] - 664s 582ms/step - loss: 5.1074e-08 - accuracy: 1.0000 - val_loss: 3.8500e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1142/1142 [==============================] - 664s 581ms/step - loss: 2.9779e-08 - accuracy: 1.0000 - val_loss: 2.2478e-08 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1142/1142 [==============================] - 662s 580ms/step - loss: 1.7412e-08 - accuracy: 1.0000 - val_loss: 1.3170e-08 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91aae49b40>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text based on sentiment\n",
        "def generate_text(sentiment):\n",
        "    # Convert sentiment to one-hot vector\n",
        "    sentiment_vector = np.array([sentiment])\n",
        "    \n",
        "    # Generate text based on the sentiment\n",
        "    generated_text = ''\n",
        "    seed_text = 'I feel '\n",
        "    for _ in range(20):  # Generate 20 words\n",
        "        encoded_text = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        padded_text = pad_sequences([encoded_text], maxlen=max_sequence_length)\n",
        "        predicted_sentiment = model.predict(padded_text)[0][0]\n",
        "        \n",
        "        if predicted_sentiment < 0.5:\n",
        "            next_word = 'bad'\n",
        "        else:\n",
        "            next_word = 'good'\n",
        "        \n",
        "        generated_text += next_word + ' '\n",
        "        seed_text += next_word + ' '\n",
        "    \n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "_nZvAT6UiCYs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text for positive sentiment\n",
        "positive_text = generate_text(1)\n",
        "print('Positive Text:', positive_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmn2EYC675lw",
        "outputId": "e424310f-a5d3-4b58-d108-1b551c2e919b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 509ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Positive Text: bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text for negative sentiment\n",
        "negative_text = generate_text(0)\n",
        "print('Negative Text:', negative_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUYbRkpQ7-XS",
        "outputId": "0ce85933-1880-4346-a551-dc9175ca9362"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Negative Text: bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad bad \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "metadata": {
        "id": "TnRpdTDI8FU7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a reference text for positive sentiment\n",
        "reference_positive = \"I feel good today. The weather is beautiful.\"\n",
        "\n",
        "# Generate a reference text for negative sentiment\n",
        "reference_negative = \"I feel bad today. Everything is going wrong.\"\n",
        "\n",
        "# Calculate BLEU score for positive sentiment\n",
        "positive_bleu = sentence_bleu([reference_positive.split()], positive_text.split())\n",
        "print('BLEU score (positive sentiment):', positive_bleu)\n",
        "\n",
        "# Calculate BLEU score for negative sentiment\n",
        "negative_bleu = sentence_bleu([reference_negative.split()], negative_text.split())\n",
        "print('BLEU score (negative sentiment):', negative_bleu)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H5AjMcH8-gj",
        "outputId": "b56e3156-e5c0-4cdd-c1f8-dcfa900e8210"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score (positive sentiment): 0\n",
            "BLEU score (negative sentiment): 8.614911585158347e-232\n"
          ]
        }
      ]
    }
  ]
}